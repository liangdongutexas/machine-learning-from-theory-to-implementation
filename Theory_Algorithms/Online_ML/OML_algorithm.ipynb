{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression admit the following online learning relation given a new data instance $\\boldsymbol{x}_i$:\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\Gamma}_{i}=&\\boldsymbol{\\Gamma}_{i-1}-\\frac{\\boldsymbol{\\Gamma}_{i-1}\\boldsymbol{x}_{i}\\boldsymbol{x}_{i}^{T}\\boldsymbol{\\Gamma}_{i-1}}{1+\\boldsymbol{x}_{i}^{T}\\boldsymbol{\\Gamma}_{i-1}\\boldsymbol{x}_{i}}\\\\\n",
    "\\hat{\\boldsymbol{\\theta}}_{i}=&\\hat{\\boldsymbol{\\theta}}_{i-1}-\\boldsymbol{\\Gamma}_{i}\\boldsymbol{x}_{i}(\\boldsymbol{x}_{i}^{T}\\hat{\\boldsymbol{\\theta}}_{i-1}-y_{i})\\\\\n",
    "iM_{i}=&(i-1)M_{i-1}+\\frac{(\\boldsymbol{x}_{i}^{T}\\hat{\\boldsymbol{\\theta}}_{i-1}-y_{i})^{2}}{1+\\boldsymbol{x}_{i}^{T}\\boldsymbol{\\Gamma}_{i-1}\\boldsymbol{x}_{i}}\n",
    "\\end{align}\n",
    "\n",
    "and the reverse relation when a instance $\\boldsymbol{x}_i$ is removed instead:\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\Gamma}_{i-1}=&\\boldsymbol{\\Gamma}_{i}+\\boldsymbol{\\Gamma}_{i-1}\\boldsymbol{x}_{i}\\boldsymbol{x}_{i}^{T}\\boldsymbol{\\Gamma}_{i},\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\hat{\\boldsymbol{\\theta}}_{i-1}=&\\hat{\\boldsymbol{\\theta}}_{i}+\\boldsymbol{\\Gamma}_{i-1}\\boldsymbol{x}_{i}(\\boldsymbol{x}_{i}^{T}\\hat{\\boldsymbol{\\theta}}_{i}-y_{i}),\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "(i-1)M_{i-1}=&iM_{i}-\\frac{(\\boldsymbol{x}_{i}^{T}\\hat{\\boldsymbol{\\theta}}_{i}-y_{i})^{2}}{1-\\boldsymbol{x}_{i}^{T}\\boldsymbol{\\Gamma}_{i}\\boldsymbol{x}_{i}}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Online Linear Regression \n",
    "The code to realize the above discussion will be provided in the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.concat([tf.ones([1000,1]),tf.random.normal([1000,19])],axis=1)\n",
    "theta=tf.range(1,21,1,dtype=tf.float32)\n",
    "Y=tf.tensordot(X,theta,axes=[1,0])+tf.random.normal([1000])\n",
    "Y=tf.expand_dims(Y,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the following stats. First we initialize the stats matrix by calculating the quantities for the sample composed of the first $d+1$ units with $d$ the feature dimensions. This is because the matrix $a$ is not reversible untill the sampel size is at least $d+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalequation(X,Y,N):\n",
    "    if N<X.shape[0]:\n",
    "        a=tf.zeros([X.shape[1],X.shape[1]])\n",
    "        b=tf.zeros([X.shape[1]])\n",
    "        c=tf.zeros([1])\n",
    "        for i in range(N):\n",
    "            a+=tf.tensordot(tf.expand_dims(X[i],1),tf.expand_dims(X[i],1),axes=[1,1])\n",
    "            b+=X[i]*Y[i]\n",
    "            c+=Y[i]*Y[i]\n",
    "\n",
    "        Gamma=tf.linalg.inv(a)\n",
    "        # use normal equation to calculate theta\n",
    "        theta_hat=tf.tensordot(Gamma,b,axes=[1,0])\n",
    "        # use normal equation to calculate Mean Square Error\n",
    "        M=(-tf.tensordot(tf.tensordot(b,Gamma,axes=[0,0]),b,axes=[0,0])+c)/N\n",
    "    \n",
    "        return [Gamma,theta_hat,M]\n",
    "    else:\n",
    "        raise ValueError('N exceeds sample size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLS(X,Y):\n",
    "    # stats=[up to current sample,[Gamma,theta,MSE]]\n",
    "    stats=[[] for i in range(X.shape[0])]\n",
    "\n",
    "    Gamma,theta_hat,M=normalequation(X,Y,X.shape[1])\n",
    "    # initialize the first d elements by the \n",
    "    for i in range(X.shape[1]):\n",
    "        stats[i].append(Gamma)\n",
    "        stats[i].append(theta_hat)\n",
    "        stats[i].append(M)\n",
    "\n",
    "\n",
    "    for i in range(X.shape[1],X.shape[0]):\n",
    "        # update Gamma matrix\n",
    "        half=tf.tensordot(stats[i-1][0],X[i],axes=[1,0]) \n",
    "        numerator=tf.tensordot(tf.expand_dims(half,1),tf.expand_dims(half,1),axes=[1,1])\n",
    "        denominator=(1+tf.tensordot(X[i],half,axes=[0,0]))\n",
    "        Gammai=stats[i-1][0]-numerator/denominator\n",
    "        stats[i].append(Gammai)\n",
    "\n",
    "        misspred=tf.tensordot(stats[i-1][1],X[i],axes=[0,0])-Y[i]\n",
    "\n",
    "        # update theta_hat   \n",
    "        theta_hati=stats[i-1][1]-tf.tensordot(stats[i][0],X[i],axes=[1,0])*misspred\n",
    "        stats[i].append(theta_hati)\n",
    "\n",
    "\n",
    "        # update mean square error\n",
    "        Mi=i/(i+1)*stats[i-1][2]+misspred*misspred/(denominator*(i+1))    \n",
    "        stats[i].append(Mi)\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check whether the iterative method of rls is reasonable close to the result given by the normal equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_rls(start,end):\n",
    "    fig,ax=plt.subplots(3)\n",
    "    for j in range(3):\n",
    "        m=[]\n",
    "        for i in range(start,end):\n",
    "            stat=normalequation(X,Y,20+i)  \n",
    "            m.append(tf.reduce_max((stats[19+i][j]-stat[j])/(stat[j])))\n",
    "            \n",
    "        ax[j].plot(range(end-start),m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats=RLS(X,Y)\n",
    "n_rls(10,800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a linear regression class capable of RLS method [here](../../my_ml_lib/supervised_learning/linear_models.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class linear_regression():\n",
    "    def __init__(self,hparameter=None,stats=None):\n",
    "        if hparameter is None:\n",
    "            self.lambd=0\n",
    "            self.sigma=0.05\n",
    "        else:\n",
    "            self.lambd=hparameter[0]\n",
    "            self.sigma=hparameter[1]\n",
    "\n",
    "        if stats is None:\n",
    "            self.Gamma=None\n",
    "            self.theta=None    \n",
    "            self.loss=None\n",
    "        else:           \n",
    "            self.Gamma=stats[0]\n",
    "            self.theta=stats[1]      \n",
    "            self.loss=stats[2]\n",
    "\n",
    "\n",
    "    \n",
    "    def online_fit(self,X,Y,feature_i,feature_name_dtype=None):\n",
    "        '''calculate stats for every binary division of the XY into XY[:i] and XY[i:] with i in range(len(XY))\n",
    "           stats_up: store information about subsample XY[:i]\n",
    "           stats_down: store information about subsample XY[i:]\n",
    "        '''\n",
    "        X_feature_i=X[:,feature_i]\n",
    "     \n",
    "        if not (feature_name_dtype is None):\n",
    "            X=X[:,feature_name_dtype[:,1]=='c']\n",
    "\n",
    "        N=len(Y)  \n",
    "        d=X.shape[1]+1\n",
    "        \n",
    "        b_split_value=None    \n",
    "        b_loss=np.Infinity  \n",
    "        b_split_left_size=1\n",
    "        b_split_right_size=N-1\n",
    "        \n",
    "        b_split_left_stats=None\n",
    "        b_split_right_stats=None\n",
    "               \n",
    "        \n",
    "        \n",
    "        # initialize stats_up\n",
    "        stats_up=[[] for i in range(len(Y))] \n",
    "        Gamma,theta_hat,M=self.partial_fit(X[:d],Y[:d])\n",
    "        # initialize the first d elements by the \n",
    "        for i in range(d):\n",
    "            stats_up[i].append(Gamma)\n",
    "            stats_up[i].append(theta_hat)\n",
    "            stats_up[i].append(M)                        # value of loss\n",
    "\n",
    "       \n",
    "        # initialize stats_down\n",
    "        if self.theta is None:\n",
    "            self.fit(X[d:],Y[d:])\n",
    "            \n",
    "        stats_down=[[] for i in range(len(Y))]\n",
    "        for i in range(d):\n",
    "            stats_down[i].append(self.Gamma)\n",
    "            stats_down[i].append(self.theta)\n",
    "            stats_down[i].append(self.loss)\n",
    "\n",
    "        \n",
    "        X=np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
    "        \n",
    "        for i in range(d,X.shape[0]-d):         \n",
    "        #updata stats_up\n",
    "            # update Gamma matrix\n",
    "\n",
    "            half=np.tensordot(stats_up[i-1][0],X[i],axes=[1,0]) \n",
    "            numerator=np.tensordot(np.expand_dims(half,1),np.expand_dims(half,1),axes=[1,1])\n",
    "            \n",
    "            denominator=(1+np.tensordot(X[i],half,axes=[0,0]))          \n",
    "            Gammai=stats_up[i-1][0]-numerator/denominator\n",
    "            stats_up[i].append(Gammai)\n",
    "\n",
    "            misspred=np.tensordot(stats_up[i-1][1],X[i],axes=[0,0])-Y[i]\n",
    "\n",
    "            # update theta_hat   \n",
    "            theta_hati=stats_up[i-1][1]-np.tensordot(stats_up[i][0],X[i],axes=[1,0])*misspred\n",
    "            stats_up[i].append(theta_hati)\n",
    "\n",
    "\n",
    "            # update mean square error\n",
    "            Mi=i/(i+1)*stats_up[i-1][2]+misspred*misspred/(denominator*(i+1))    \n",
    "            stats_up[i].append(Mi)\n",
    "            \n",
    "         #updata stats_down   \n",
    "            # update Gamma matrix\n",
    "            half=np.tensordot(stats_down[i-1][0],X[i-1],axes=[1,0]) \n",
    "            numerator=np.tensordot(np.expand_dims(half,1),np.expand_dims(half,1),axes=[1,1])\n",
    "            denominator=(1-np.tensordot(X[i-1],half,axes=[0,0]))\n",
    "            Gammai=stats_down[i-1][0]+numerator/denominator\n",
    "            stats_down[i].append(Gammai)\n",
    "\n",
    "            misspred=np.tensordot(stats_down[i-1][1],X[i-1],axes=[0,0])-Y[i-1]\n",
    "\n",
    "            # update theta_hat   \n",
    "            theta_hati=stats_down[i-1][1]+np.tensordot(stats_down[i][0],X[i-1],axes=[1,0])*misspred\n",
    "            stats_down[i].append(theta_hati)\n",
    "\n",
    "\n",
    "            # update mean square error\n",
    "            Mi=(N-(i-1))/(N-i)*stats_down[i-1][2]-misspred*misspred/(denominator*(N-i))    \n",
    "            stats_down[i].append(Mi)\n",
    "            \n",
    "        # find out the best split point\n",
    "            if  X_feature_i[i]!=X_feature_i[i-1] or i==len(Y):\n",
    "                if stats_up[i-1][-1]*i/N+stats_down[i][-1]*(N-i)/N<b_loss:\n",
    "                    b_split_left_stats=stats_up[i-1]\n",
    "                    b_split_right_stats=stats_down[i]\n",
    "                    b_split_left_size=i\n",
    "                    b_split_right_size=N-i\n",
    "                    \n",
    "                    b_loss=stats_up[i-1][-1]*i/N+stats_down[i][-1]*(N-i)/N\n",
    "                    b_split_value=X_feature_i[i-1]\n",
    "                   \n",
    "        return b_split_left_stats,b_split_right_stats,b_split_left_size,b_split_right_size,b_split_value,b_loss\n",
    "        #return stats_up,stats_down\n",
    "    \n",
    "    def batch_fit(self,X,Y,feature_i,feature_name_dtype=None):\n",
    "        '''calculate stats for every binary division of the XY into XY[:,feature_i]==value and XY[:,feature_i]!=value \n",
    "           for all possible values of feature_i\n",
    "           omega_batch,loss_batch: information about subsample XY[:,feature_i]==value\n",
    "           omega_ba_null,loss_ba_null: information about subsample XY[:,feature_i]!=value \n",
    "        '''\n",
    "        X_feature_i=X[:,feature_i]\n",
    "        \n",
    "        if not (feature_name_dtype is None):\n",
    "            X=X[:,feature_name_dtype[:,1]=='c']                 \n",
    "       \n",
    "        N=len(Y)\n",
    "               \n",
    "        d=X.shape[1]+1\n",
    "        \n",
    "        b_split_left_stats=None\n",
    "        b_split_right_stats=None\n",
    "        b_split_left_size=1\n",
    "        b_split_right_size=N-1\n",
    "        \n",
    "        best_split_value=None\n",
    "        best_loss=np.Infinity\n",
    "        \n",
    "        # initialize stats_down\n",
    "\n",
    "        if self.theta is None:\n",
    "            self.fit(X[d:],Y[d:])\n",
    "\n",
    "        \n",
    "        X=np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
    "\n",
    "        stats_batch=[]\n",
    "        stats_ba_null=[]\n",
    "        \n",
    "        #l,r: left bound and right bound of the batch\n",
    "        l=0\n",
    "        r=1\n",
    "        while r<len(Y):\n",
    "            while r<len(X) and X_feature_i[r]==X_feature_i[r-1]:\n",
    "                r+=1\n",
    "                \n",
    "            stats_batch=self.partial_fit(X[l:r],Y[l:r])\n",
    "            stats_ba_null=self.partial_fit(np.concatenate(X[:l],X[r:],axis=0),np.concatenate(Y[:l],Y[r:],axis=0))\n",
    "                   \n",
    "            if stats_batch[-1]*(r-l)/N+stats_ba_null[-1]*(N-(r-l))/N<best_loss:\n",
    "                b_split_left_stats=stats_batch\n",
    "                b_split_right_stats=stats_ba_null\n",
    "                b_split_left_size=r-l\n",
    "                b_split_right_size=N-(r-l)\n",
    "                \n",
    "                best_loss=stats_batch[-1]*(r-l)/N+stats_ba_null[-1]*(N-(r-l))/N\n",
    "                best_split_value=X_feature_i[r-1]               \n",
    "            \n",
    "            l=r\n",
    "            r+=1\n",
    "            \n",
    "        return b_split_left_stats,b_split_right_stats,b_split_left_size,b_split_right_size,best_split_value,best_loss\n",
    "            \n",
    "                  \n",
    "    def partial_fit(self,X,Y,feature_name_dtype=None): \n",
    "        if not (feature_name_dtype is None):\n",
    "            X=np.concatenate((X[:,feature_name_dtype[:,1]=='c'],np.ones((X.shape[0],1))),axis=1)\n",
    "        else:\n",
    "            X=np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
    "            \n",
    "        N=len(Y)    \n",
    "        a=np.zeros([X.shape[1],X.shape[1]])\n",
    "        b=np.zeros([X.shape[1]])\n",
    "        c=np.zeros([1])\n",
    "        for i in range(N):\n",
    "            a+=np.tensordot(np.expand_dims(X[i],1),np.expand_dims(X[i],1),axes=[1,1])\n",
    "            b+=X[i]*Y[i]\n",
    "            c+=Y[i]*Y[i]\n",
    "\n",
    "        Gamma=np.linalg.inv(a+self.sigma*np.identity(X.shape[1]))\n",
    "        # use normal equation to calculate theta\n",
    "        theta_hat=np.tensordot(Gamma,b,axes=[1,0])\n",
    "        # use normal equation to calculate Mean Square Error\n",
    "        M=(-np.tensordot(np.tensordot(b,Gamma,axes=[0,0]),b,axes=[0,0])+c)/N\n",
    " \n",
    "        return [Gamma,theta_hat,M]\n",
    "    \n",
    "    def fit(self,X,Y,feature_name_dtype=None):    \n",
    "        if not (feature_name_dtype is None):\n",
    "            X=np.concatenate((X[:,feature_name_dtype[:,1]=='c'],np.ones((X.shape[0],1))),axis=1)\n",
    "        else:\n",
    "            X=np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
    "            \n",
    "        a=np.zeros([X.shape[1],X.shape[1]])\n",
    "        b=np.zeros([X.shape[1]])\n",
    "        c=np.zeros([1])\n",
    "        for i in range(X.shape[0]):\n",
    "            a+=np.tensordot(np.expand_dims(X[i],1),np.expand_dims(X[i],1),axes=[1,1])\n",
    "            b+=X[i]*Y[i]\n",
    "            c+=Y[i]*Y[i]\n",
    "\n",
    "        Gamma=np.linalg.inv(a+self.sigma*np.identity(X.shape[1]))\n",
    "        # use normal equation to calculate theta\n",
    "        theta_hat=np.tensordot(Gamma,b,axes=[1,0])\n",
    "        # use normal equation to calculate Mean Square Error\n",
    "        M=(-np.tensordot(np.tensordot(b,Gamma,axes=[0,0]),b,axes=[0,0])+c)/X.shape[0]\n",
    "        \n",
    "        self.Gamma=Gamma\n",
    "        self.theta=theta_hat\n",
    "        self.loss=M\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self,X,feature_name_dtype=None):\n",
    "          \n",
    "        if len(np.shape(X))==2:\n",
    "            if not (feature_name_dtype is None):\n",
    "                X=np.concatenate((X[:,feature_name_dtype[:,1]=='c'],np.ones((X.shape[0],1))),axis=1)\n",
    "            else:\n",
    "                X=np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
    "\n",
    "            return np.tensordot(self.theta,X,axes=[0,1])   \n",
    "        \n",
    "        elif len(np.shape(X))==1:\n",
    "            if not (feature_name_dtype is None):\n",
    "                X=np.concatenate((X[feature_name_dtype[:,1]=='c'],[1]),axis=0)\n",
    "            else:\n",
    "                X=np.concatenate((X,[1]),axis=0)               \n",
    "            return np.array([np.tensordot(self.theta,X,axes=[0,0])])\n",
    "        else:\n",
    "            raise ValueError('The shape of input data is incorrect')\n",
    "    def model_description(self):\n",
    "        model_eq='y='\n",
    "        for i in range(len(self.theta)-1):\n",
    "            model_eq+='+{}*X_{}'.format(round(self.theta[i],5),i) if self.theta[i]>=0 \\\n",
    "                      else '{}*X_{}'.format(round(self.theta[i]),i)\n",
    "        model_eq+='{}'.format(self.theta[-1])\n",
    "        return model_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class average_regression():\n",
    "    def __init__(self,hparameter=0,stats=None):\n",
    "        self.lambd=hparameter\n",
    "        if stats is None:\n",
    "            self.parameter=0     \n",
    "            self.loss=0\n",
    "        else:\n",
    "            self.parameter=stats[0]      \n",
    "            self.loss=stats[1]\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    def online_fit(self,X,Y,feature_i,feature_name_dtype=None):\n",
    "        '''calculate stats for every binary division of the XY into XY[:i] and XY[i:] with i in range(len(XY))\n",
    "           stats_up: store information about subsample XY[:i]\n",
    "           stats_down: store information about subsample XY[i:]\n",
    "        '''\n",
    "        ## quantites record information about the best split\n",
    "        N=len(Y)\n",
    "        \n",
    "        b_split_value=None    \n",
    "        b_loss=np.Infinity  \n",
    "        b_split_left_size=1\n",
    "        b_split_right_size=N-1\n",
    "        \n",
    "        b_split_left_stats=None\n",
    "        b_split_right_stats=None\n",
    "               \n",
    "        \n",
    "        \n",
    "        # initialize stats_up\n",
    "        stats_up=[[] for i in range(len(Y))] \n",
    "        stats_up[0].append(self.partial_fit(X[0:1],Y[0:1]))                       # value of omega\n",
    "        stats_up[0].append(self.loss_cal(X[0:1],Y[0:1]))                          # value of loss\n",
    "\n",
    "       \n",
    "        # initialize stats_down\n",
    "        if not self.parameter:\n",
    "            self.fit(X,Y)\n",
    "        if not self.loss:\n",
    "            self.loss=self.loss_cal(X,Y)\n",
    "\n",
    "        stats_down=[[] for i in range(len(Y))]\n",
    "        stats_down[0].append(self.parameter)\n",
    "        stats_down[0].append(self.loss)\n",
    "        \n",
    "        \n",
    "        for i in range(1,len(Y)):\n",
    "            \n",
    "            # update stats_up\n",
    "            omega_i=stats_up[i-1][0]*i/(i+1)+Y[i,0]/(1+self.lambd)/(i+1)\n",
    "            loss_i=((stats_up[i-1][1]+(1+self.lambd)*stats_up[i-1][0]**2)*i/(i+1)+Y[i,0]**2/(i+1))\\\n",
    "                   -(1+self.lambd)*(omega_i**2)\n",
    "            stats_up[i].append(omega_i)\n",
    "            stats_up[i].append(loss_i)\n",
    "\n",
    "\n",
    "            # update stats_down\n",
    "            omega_i_1=stats_down[i-1][0]*(N-i+1)/(N-i)-Y[i-1,0]/(1+self.lambd)/(N-i)\n",
    "            loss_i_1=((stats_down[i-1][1]+(1+self.lambd)*stats_down[i-1][0]**2)*(N-i+1)/(N-i)-Y[i-1,0]**2/(N-i))\\\n",
    "                   -(1+self.lambd)*(omega_i_1**2)\n",
    "            stats_down[i].append(omega_i_1)\n",
    "            stats_down[i].append(loss_i_1)\n",
    "            \n",
    "            # find out the best split point\n",
    "            if X[i,feature_i]!=X[i-1,feature_i] or i==len(Y):\n",
    "                if stats_up[i-1][-1]*i/N+stats_down[i][-1]*(N-i)/N<b_loss:\n",
    "                    b_split_left_stats=stats_up[i-1]\n",
    "                    b_split_right_stats=stats_down[i]\n",
    "                    b_split_left_size=i\n",
    "                    b_split_right_size=N-i\n",
    "                    \n",
    "                    b_loss=stats_up[i-1][-1]*i/N+stats_down[i][-1]*(N-i)/N\n",
    "                    b_split_value=X[i-1,feature_i]\n",
    "                   \n",
    "        return b_split_left_stats,b_split_right_stats,b_split_left_size,b_split_right_size,b_split_value,b_loss\n",
    "    \n",
    "    def batch_fit(self,X,Y,feature_i,feature_name_dtype=None):\n",
    "        '''calculate stats for every binary division of the XY into XY[:,feature_i]==value and XY[:,feature_i]!=value \n",
    "           for all possible values of feature_i\n",
    "           omega_batch,loss_batch: information about subsample XY[:,feature_i]==value\n",
    "           omega_ba_null,loss_ba_null: information about subsample XY[:,feature_i]!=value \n",
    "        '''\n",
    "        N=len(Y)\n",
    "        \n",
    "        b_split_left_stats=None\n",
    "        b_split_right_stats=None\n",
    "        b_split_left_size=1\n",
    "        b_split_right_size=N-1\n",
    "        \n",
    "        best_split_value=None\n",
    "        best_loss=np.Infinity\n",
    "        \n",
    "        # initialize stats_down\n",
    "        if not self.parameter:\n",
    "            self.fit(X,Y)\n",
    "        if not self.loss:\n",
    "            self.loss=self.loss_cal(X,Y)\n",
    "            \n",
    "        omega_tot=self.parameter\n",
    "        loss_tot=self.loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        #l,r: left bound and right bound of the batch\n",
    "        l=0\n",
    "        r=1\n",
    "        while r<len(Y):\n",
    "            while r<len(X) and X[r,feature_i]==X[r-1,feature_i]:\n",
    "                r+=1\n",
    "                \n",
    "            omega_batch=self.partial_fit(X[l:r],Y[l:r])\n",
    "            loss_batch=self.loss_cal(X[l:r],Y[l:r])\n",
    "                       \n",
    "            omega_ba_null=omega_tot*N/(N-(r-l))-np.sum(Y[l:r])/(1+self.lambd)/(N-(r-l))\n",
    "            loss_ba_null=((loss_tot+(1+self.lambd)*omega_tot**2)*N/(N-(r-l))-np.sum(Y[l:r]**2)/(N-(r-l)))\\\n",
    "                   -(1+self.lambd)*(omega_ba_null**2)\n",
    "            \n",
    "            \n",
    "            if loss_batch*(r-l)/N+loss_ba_null*(N-(r-l))/N<best_loss:\n",
    "                b_split_left_stats=[omega_batch,loss_batch]\n",
    "                b_split_right_stats=[omega_ba_null,loss_ba_null]\n",
    "                b_split_left_size=r-l\n",
    "                b_split_right_size=N-(r-l)\n",
    "                \n",
    "                best_loss=loss_batch*(r-l)/N+loss_ba_null*(N-(r-l))/N\n",
    "                best_split_value=X[r-1,feature_i]               \n",
    "            \n",
    "            l=r\n",
    "            r+=1\n",
    "            \n",
    "        return b_split_left_stats,b_split_right_stats,b_split_left_size,b_split_right_size,best_split_value,best_loss\n",
    "            \n",
    "                  \n",
    "    def partial_fit(self,X,Y,feature_name_dtype=None):\n",
    "        # conventional stochastic gradient method to train model\n",
    "        return np.mean(Y)/(1+self.lambd)\n",
    "    \n",
    "    def fit(self,X,Y,feature_name_dtype=None):\n",
    "        # conventional stochastic gradient method to train model\n",
    "        self.parameter=np.mean(Y)/(1+self.lambd)\n",
    "    \n",
    "    def predict(self,X,feature_name_dtype=None):\n",
    "        if len(np.shape(X))==2:\n",
    "            return np.array([self.parameter for i in range(X.shape[0])])        \n",
    "        elif len(np.shape(X))==1:\n",
    "            return np.array([self.parameter])\n",
    "        else:\n",
    "            raise ValueError('The shape of input data is incorrect')\n",
    "    \n",
    "    def loss_cal(self,X,Y,feature_name_dtype=None):\n",
    "        return np.mean(Y**2)-np.mean(Y)**2/(1+self.lambd)\n",
    "    \n",
    "    def model_description(self):\n",
    "        return 'predicted value is {}'.format(self.parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
