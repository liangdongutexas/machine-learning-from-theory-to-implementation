{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HMM](HMM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hidden Markov Model is represented by the above graph. The joint probability distribution function of the model can be derived from the graph as:\n",
    "\\begin{align}\n",
    "p(\\{\\boldsymbol{X}_i\\},\\{\\boldsymbol{O}_j\\})=p(\\boldsymbol{X}_0)\\prod_{m=1}^{T-1} p(\\boldsymbol{X}_m|\\boldsymbol{X}_{m-1})\\prod_{n=0}^{T-1}p(\\boldsymbol{O}_n|\\boldsymbol{X}_n).\n",
    "\\end{align}\n",
    "From the above expression, we can see that\n",
    "\\begin{align}\n",
    "p(\\{\\boldsymbol{X}\\})=&\\sum_{\\{\\boldsymbol{O}_n\\}}p(\\boldsymbol{X}_0)\\prod_{m=1}^{T-1} p(\\boldsymbol{X}_m|\\boldsymbol{X}_{m-1})\\prod_{n=0}^{T-1}p(\\boldsymbol{O}_n|\\boldsymbol{X}_n)\\\\\n",
    "                     =& p(\\boldsymbol{X}_0)\\prod_{m=1}^{T-1} p(\\boldsymbol{X}_m|\\boldsymbol{X}_{m-1}),\n",
    "\\end{align}\n",
    "which is simply the Markov Chain distribution.\n",
    "Since $\\boldsymbol{X}$  is hidden, the parameter in the model can be determined with MLE by maximizing the following \n",
    "\\begin{align}\n",
    "p(\\{\\boldsymbol{O}\\})=\\sum_{\\{\\boldsymbol{X}_m\\}}p(\\boldsymbol{X}_0)\\prod_{m=1}^{T-1} p(\\boldsymbol{X}_m|\\boldsymbol{X}_{m-1})\\prod_{n=0}^{T-1}p(\\boldsymbol{O}_n|\\boldsymbol{X}_n).\n",
    "\\end{align}\n",
    "The summation is very similar to the path integral in physics.\n",
    "Again the summation cause a problem, we can use expectation maximization:\n",
    "* in the E step, calculate $p_{old}(\\{\\boldsymbol{X}\\}|\\{\\boldsymbol{O}\\})$.\n",
    "* in the M step, maximize\n",
    "\\begin{align}\n",
    "\\mathcal{L}=\\sum_{\\{\\boldsymbol{X}\\}}p_{old}(\\{\\boldsymbol{X}\\}|\\{\\boldsymbol{O}\\})\\log p(\\{\\boldsymbol{X}_i\\},\\{\\boldsymbol{O}_j\\})\n",
    "\\end{align}\n",
    "\n",
    "$\\mathcal{L}$ can be written in the following form:\n",
    "\\begin{align}\n",
    "\\mathcal{L}=\\sum_{\\{\\boldsymbol{X}\\}}p_{old}(\\{\\boldsymbol{X}\\}|\\{\\boldsymbol{O}\\})[\\log p(\\boldsymbol{X}_0)+\\sum_{m=1}^{T-1}\\log p(\\boldsymbol{X}_m|\\boldsymbol{X}_{m-1})+\\sum_{n=0}^{T-1}\\log p(\\boldsymbol{O}_n|\\boldsymbol{X}_n)]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\{\\boldsymbol{X}\\}$ are discrete variables and the probability itself is treated as parameter, then we have\n",
    "\\begin{align}\n",
    "p(\\boldsymbol{X}_0)=&p_{old}(\\boldsymbol{X}_0|\\{\\boldsymbol{O}\\}),\\\\\n",
    "p(\\boldsymbol{X}_m|\\boldsymbol{X}_{m-1})=&\\frac{p_{old}(\\boldsymbol{X}_m,\\boldsymbol{X}_{m-1}|\\{\\boldsymbol{O}\\})}{p_{old}(\\boldsymbol{X}_{m-1}|\\{\\boldsymbol{O}\\})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
