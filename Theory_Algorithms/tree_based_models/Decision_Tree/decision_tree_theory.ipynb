{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "\n",
    "![what-is-a-decision-tree](what-is-a-decision-tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental logic behind decision tree is that by dividing the data set into two and training the same model separately, the sum of loss is smaller than training the same model on the total data set.\n",
    "\n",
    "Suppose we have a model that is trained by minimizing the following loss function:\n",
    "$$\n",
    "\\mathcal{L}=l(\\{\\hat{y}_i\\},\\{y_i\\}),\n",
    "$$\n",
    "e.g., $\\mathcal{L}=\\frac{1}{N}\\sum_{i=1}^{N}(\\hat{y}_i-y_i)^2$.\n",
    "\n",
    "Here and after, we assume the loss function has the property that it is invariant under copying the training data set .e.g. the mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training the model with all the data set, we can also divide the training data into two parts according to some condition: $\\{y_i\\}_1$ and $\\{y_i\\}_2$, then train the same model seperately on this two subsets. Two loss functions are then given by\n",
    "\\begin{align}\n",
    "\\mathcal{L}_1=&l(\\{\\hat{y}_i\\}_1,\\{y_i\\}_1),\\\\\n",
    "\\mathcal{L}_2=&l(\\{\\hat{y}_i\\}_2,\\{y_i\\}_2).\n",
    "\\end{align}\n",
    "Then the average loss in most cases is smaller than the total loss\n",
    "$$\n",
    "\\mathcal{L}_1 \\frac{N_1}{N} + \\mathcal{L}_2 \\frac{N_2}{N}\\leq \\mathcal{L}\n",
    "$$\n",
    "\n",
    "The reason is that if the two subsets obey the same distribution, then the average loss is the same as the total loss. However, when there is significant discrepancy between the two subsets, it is possible the model **can detect this discrepancy** and adapt to two different models either of which fits better on its own subset and worse on the other subset. As a result, the average loss is smaller than the total. Of course, this reasoning relies on the assumptions that the bias of the model fist the subset and the discrepancy falls into the range of variance of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we give an example. Consider the model to be linear regression with  the loss function given by the mean square error, we divide a data sample of size $M+N$  into two subsets with size $M$ and $N$ respectively. In this picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7fd9ed3ee0>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_1=np.arange(0,5,0.01)\n",
    "X_1=np.expand_dims(X_1,axis=1)\n",
    "Y_1=2*X_1+1+np.random.randn(500,1)\n",
    "\n",
    "X_2=np.arange(5,10,0.01)\n",
    "X_2=np.expand_dims(X_2,axis=1)\n",
    "Y_2=5*X_2-14+np.random.randn(500,1)\n",
    "\n",
    "X=np.concatenate((X_1,X_2),axis=0)\n",
    "Y=np.concatenate((Y_1,Y_2),axis=0)\n",
    "\n",
    "lrclf_1=LinearRegression()\n",
    "lrclf_1.fit(X_1,Y_1)\n",
    "lrclf_2=LinearRegression()\n",
    "lrclf_2.fit(X_2,Y_2)\n",
    "lrclf=LinearRegression()\n",
    "lrclf.fit(X,Y)\n",
    "\n",
    "plt.scatter(X_1,Y_1,s=1)\n",
    "plt.scatter(X_2,Y_2,s=1)\n",
    "plt.plot(X_1,lrclf_1.predict(X_1))\n",
    "plt.plot(X_2,lrclf_2.predict(X_2))\n",
    "plt.plot(X,lrclf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see from the image above if a decision node is applied to divide the data into $X<=5$ and $X>5$ before linear regression, the loss will be smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data set 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4      5.0  \n",
       "1      9.8      5.0  \n",
       "2      9.8      5.0  \n",
       "3      9.8      6.0  \n",
       "4      9.4      5.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redwine=pd.read_csv(\"../../../data_set/winequality-red.csv\")\n",
    "redwine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables=np.array(redwine.values.tolist(),dtype=np.float32)\n",
    "X=tables[:,:-1]\n",
    "Y=tables[:,-1:]\n",
    "feature_name_dtype=[[redwine.columns[i],'c'] for i in range(len(redwine.columns)-1)]\n",
    "# cross validation:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_ml_lib.supervised_learning import tree_based_models as tbm\n",
    "from my_ml_lib.supervised_learning import linear_models as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436857595527078"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_node=tbm.tree_node_decorator(lm.linear_regression,hparameter=0)           # this is a class type not class object\n",
    "decision_tree=tbm.decision_tree_decorator(tree_node,max_depth=10,gamma=0.1,min_sample_size=100)()    # this is a class object\n",
    "decision_tree.fit(X=X_train,Y=Y_train,feature_name_dtype=feature_name_dtype)\n",
    "np.sqrt(np.mean((decision_tree.predict(X_test)-Y_test)**2))\n",
    "decision_tree.plot_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(min_samples_split=300)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.936422914121321"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sktree=tree.DecisionTreeRegressor(min_samples_split=300)\n",
    "sktree.fit(X_train,Y_train)\n",
    "np.sqrt(np.mean((sktree.predict(X_test)-Y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieve higher accuracy than the sklearn module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# information gain for classification tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain after the first decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy $H(Y)$:\n",
    "$$\n",
    "H(Y) \\equiv -\\int dY \\log p(Y)\n",
    "$$\n",
    "By dividing the sample into subgroups, it is expected the **divided state** is more **ordered** than the original **state**. If we use entropy to demonstrate the **disorder** of a state,this knowledge gain is describe by:\n",
    "\\begin{align}\n",
    "H(Y)-\\hat{H}(Y|A),\n",
    "\\end{align}\n",
    "where and in the following we adopt the convention of using hat to denote this quantity is model related while without hat means it is a population related quantity.\n",
    "\n",
    "We can fruther derive its expression in terms of $X$. The disorder of the whole population is\n",
    "\\begin{align}\n",
    "H(XY)=-\\int dXdY p(XY)\\log_2p(XY) \\label{Eq.(1)}\n",
    "\\end{align}\n",
    "Every time when a **decision** is made, the predictor space is partitioned into subspaces $\\{A_i\\}$, e.g. $i=0,1$ for binary decision tree. Then according to the property of entropy:\n",
    "\\begin{align}\n",
    "H(XY)=\\hat{H}(A)+\\hat{H}(XY|A) \\label{Eq.(2)}\n",
    "\\end{align}\n",
    "where $H(A)$ is the entropy of $A$ and $H(XY|A)$ the conditional: \n",
    "\\begin{align}\n",
    "\\hat{H}(A)&=-\\sum_i p(A_i)\\log_2 p(A_i), \\label{Eq.(3)} \\\\ \n",
    "\\hat{H}(XY|A)&=-\\sum_i p(A_i)\\int dXdY p(XY|A_i)\\log_2 p(XY|A_i) \\label{Eq.(4)}.\n",
    "\\end{align}\n",
    "However, we only care about the purity of the outcome variable. So utilizing the property of conditional entropy\n",
    "\\begin{align}\n",
    "H(XY)=H(Y)+H(X|Y), \\label{Eq.(5)}\n",
    "\\end{align}\n",
    "We have\n",
    "\\begin{align}\n",
    "H(Y)-\\hat{H}(Y|A)=\\hat{H}(A)+\\hat{H}(X|YA)-H(X|Y). \\label{Eq.(6)}\n",
    "\\end{align}\n",
    "The right hand side determines whether the decision gains knowledge or not. \n",
    "We should notice here that the **decision** is made with respect to the predictor but the **disorder** is measured with respect to the outcome.\n",
    "\n",
    "Although it is interesting to analyze whether the right hand side is positive or not. In reality, we only need to focus on $\\hat{H}(Y|A)$ and minimize it such that $\\hat{H}(Y)-\\hat{H}(Y|A)$ is positive and knowledge is gained at maximal. If on the other hand $\\hat{H}(Y)-\\hat{H}(Y|A)$ is negative then the decision is bad and no further devision is needed. In the worst case $X$ and $Y$ are independent, both sides of the equation is simply zero. So as long as there is correlation, we should always achieve a positive knowledge gain unless there is false information contained in the data. \n",
    "\n",
    "The logic behind information gaining is the following: consider a unit in the sample, without the help of decision tree its probability falling into the values of $\\{Y_i\\}$ is descirbed by $p(Y)$, thus the information we know about this unit with respect to its outcome variables is $-H(Y)$. (The more prior information we have, the less entropy). However, with the help of decision tree, it tells you which subspace this unit belongs to, thus the information we know about this unit with respect to $Y$ becomes $-\\hat{H}(Y|A)$. If $H(Y)-\\hat{H}(Y|A)>0$, we gain information with the help of decision tree. \n",
    "\n",
    "It is also clear that the maximum information the model can provide to us is $H(Y)-H(Y|X)$ when the partition $A$ is an exhaustive partition of all possible realization of $X$ or equivalent in the sense of determining $Y$ i.e. $A=X$. However, the more divisions we make, the higher risk of giving the wrong prediction since the sample may not represents the population. Also, it is not impossible nor economic to implement exhaustive divisions. I think the trick in designing a decision tree algorithm is to find the most efficient **decisions** such that the algorithm achieves an expected accuray with minimal steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we treat decision tree as a knowledge gaining process, to measure its performance, we can use the total knowledge gained which is the entropy difference between the two conditional probabilities:\n",
    "\\begin{align}\n",
    "|\\hat{H}(Y|A)-H(Y|X)|.\\\n",
    "\\end{align}\n",
    "Although $H(Y|X)$ is unknown,we can utilize the property of entropy:\n",
    "\\begin{align}\n",
    "H(XY)=H(X)+H(Y|X),\n",
    "\\end{align}\n",
    "then it becomes\n",
    "\\begin{align}\n",
    "|\\hat{H}(Y|A)+H(X)-H(XY)|.\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![what-is-a-decision-tree](dt_entropy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully training a decision, questions are often asked which predictor plays a major role in determining a particular outcome. This qutesion can be answered from the perspective of entropy introduced above. We use the symbol $\\{A^0,A^1,...A^i,...A^n\\}$  to denote a process of partition happened in the decision tree. $A^0$ is the decision made about the root, $A^1$ is the decision made given the root partition. So each decision depends on all the decisions before it. This hierarchy structure is one of the reasons that decision tree algorithm is not stable against small change of sample. We can write the total entropy of the sample in terms of this hierarchy structure:\n",
    "\\begin{align}\n",
    "\\Delta H^0(Y)&=H(Y)-\\hat{H}(Y|A^0), \\\\\n",
    "\\Delta H^1(Y|A^0)&=\\hat{H}(Y|A^0)-\\hat{H}(Y|A^0A^1),\\\\\n",
    "...\\\\\n",
    "\\Delta H^{n-1}(Y|A^0...A^{n-1})&=\\hat{H}(Y|A^0...A^{n-1})-\\hat{H}(Y|A^0...A^n),\n",
    "\\end{align}\n",
    "where\n",
    "\\begin{align}\n",
    "\\hat{H}(Y|A^0...A^l)=-\\sum_{A^0_i...A^l_j}p(A^0_i...A^l_j)\\int dY p(Y|A^0_i...A^l_j)\\log_2p(Y|A^0_i...A^l_j),\n",
    "\\end{align}\n",
    "and \n",
    "\\begin{align}\n",
    "p(A^0...A^l)=p(A^0)p(A^1|A^0)p(A^2|A^1A^0)...p(A^l|A^0...A^{l-1}).\n",
    "\\end{align}\n",
    "\n",
    "In terms of code, we only need to look at a particular node, calculate its entropy deduction and multiply the deduction by the probability of reaching that node. Because each node represents a particular value of $A^i_j$. We then have to classify the entropy deduction by the feature involved. By the contribution to entropy deduction, we can rank the most important features in the decision tree. \n",
    "Further more, when $Y$ takes value for all the possibility of outcome, it gives the average contribution of each feature. But we can let $Y$ take two value i.e. whether belong to a particular category or not. Then the same procedure gives the importance of features in determining this particular outcome.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here](../../../my_ml_lib/supervised_learning/Decision_Tree.py) is the implementation of a classification tree. It capable of dealing with both categorical and ordinal data. It also gives a report of the predictor that contributes most in the information again with respect to a particular class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
