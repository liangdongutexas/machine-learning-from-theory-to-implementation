{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell is the model class. \n",
    "Its __call__ method returns the predicted FPS according to aformentioned formula.\n",
    "Its load_variables method loads previously trained parameters which will be used by the __call__ method to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer():\n",
    "    def __init__(self,shape=None,activation=None):\n",
    "        self.shape=shape\n",
    "        self.activation=activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_action():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # define all the metric loss functions\n",
    "        self.losses={'binary_crossentropy':tf.keras.losses.binary_crossentropy,\n",
    "          'MSE': tf.keras.losses.MSE,'CategoricalCrossentropy':tf.keras.losses.CategoricalCrossentropy,\\\n",
    "                   'categorical_crossentropy':tf.keras.losses.categorical_crossentropy\n",
    "}\n",
    "        \n",
    "    ## uses tensorflow to do backpropagation onece for each epoch.\n",
    "    def train_one_step(self,X,Y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predict = self.predict(X)\n",
    "            loss=self.compute_loss(predict, Y)\n",
    "            optimizer=self.optimizer\n",
    "            # compute gradient\n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            # update to weights\n",
    "            optimizer.apply_gradients(zip(grads, self.trainable_variables))   \n",
    "        \n",
    "     \n",
    "    def compute_loss(self,predict, Y):       \n",
    "        return self.losses[self.loss](predict,Y)\n",
    "    \n",
    "    def save_model(self,filename):\n",
    "        stored_variables=np.array([i.numpy() for i in self.trainable_variables])\n",
    "        np.save(filename, stored_variables,allow_pickle=True, fix_imports=True)\n",
    "        print('model has been saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shape is a list of tuples.\n",
    "## The i_th element represents the tensor structure of the i_th layer.\n",
    "## The 0_th element represents the shape of the input.\n",
    "## The -1_th element represents the shape of the output.\n",
    "class sequential(train_action):\n",
    "    \n",
    "    def __init__(self,layers):       \n",
    "        super().__init__()\n",
    "        \n",
    "        ## attribute cannot be a function but can be a dictionary of functions.\n",
    "        self.activations={'relu':tf.keras.activations.relu,'elu':tf.keras.activations.elu,\\\n",
    "            'sigmoid':tf.keras.activations.sigmoid, 'selu': tf.keras.activations.selu,\n",
    "                        'softmax':tf.keras.activations.softmax}\n",
    "\n",
    "        \n",
    "        self.layers=layers\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        self.trainable_variables=[]\n",
    "\n",
    "        for i in range(len(layers)-1):\n",
    "            weight=tf.Variable(tf.random.truncated_normal(shape=self.layers[i].shape+self.layers[i+1].shape))\n",
    "            bias=tf.Variable(tf.zeros(shape=self.layers[i+1].shape))\n",
    "            self.weights.append(weight) \n",
    "            self.bias.append(bias) \n",
    "        self.trainable_variables=self.weights+self.bias\n",
    "        \n",
    "    def predict(self,X=None):\n",
    "        X=tf.cast(X,tf.float32)\n",
    "        Y=X\n",
    "        for i in range(0,len(self.layers)-1): #i is the layer we are right now and the\n",
    "                                              # data will propagate to the next layer\n",
    "                                              # so the we should use the activation function in the next layer \n",
    "            \n",
    "            # the shape of current layer, the first one is the batch size\n",
    "            backdim=self.layers[i].shape \n",
    "            \n",
    "            # the shape of next layer\n",
    "            frontdim=self.layers[i+1].shape      \n",
    "            bl=len(backdim)\n",
    "            \n",
    "            \n",
    "            Y=tf.tensordot(Y,self.weights[i],\\\n",
    "                           axes=[np.arange(1,bl+1),np.arange(0,bl)])+self.bias[i]\n",
    "            if self.layers[i+1].activation:\n",
    "                Y=self.activations[self.layers[i+1].activation](Y)\n",
    "             \n",
    "\n",
    "\n",
    "        return Y\n",
    "    \n",
    "    def compile(self,loss=None,optimizer=None):\n",
    "        # loss is string name of the tf.keras.losses functions\n",
    "        # optimizer is a class for most cases in tensorflow, so the optimizer here is a class\n",
    "        self.loss=loss\n",
    "        self.optimizer=optimizer\n",
    "        \n",
    "    def train(self,X,Y,epochs=100,epochgroup=10,save_name=None):       \n",
    "        for epoch in range(epochs): \n",
    "            if epoch%epochgroup==0:\n",
    "                predict=self.predict(X)\n",
    "                print('for epoch {}, {} is {}'\\\n",
    "                  .format(epoch,self.loss,tf.math.reduce_mean(self.compute_loss(predict,Y))))\n",
    "            self.train_one_step(X,Y)  \n",
    "        if save_name:\n",
    "            self.save_model(save_name)\n",
    "    def weight_visual(self):\n",
    "        pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
